Automatic localization and classification of surgical tools in endoscopic videos has many advantages, especially as an auxiliary task to provide cheaper annotated datasets for segmentation-tasks, that can ultimately improve current endeavours in medical practices and research. We managed to score a mean of over 0.95 and 0.70 average precision across all classes in detection and localization respectively on the M2CAI2016-dataset. 
These results are very satisfactory, although we hoped for better localization-results. We achieved them by combining a ResNet-18-backbone with stride 2$\times$2 with a 1$\times$1-kernel convolution-layer to generate the heatmaps for the classes and min-max-pooling for classification. 
We trained with stochastic gradient descent and batch-sizes ranging from 20-50 and the multi-label soft margin loss as the loss function.
The hyper-parameters were successfully improved over the base-parameters by applying a Gaussian process on a small set of hyper-parameters and model-performance-indicators over 50 epochs. One possible improvement here might be to combine Bayesian optimization with Gaussian processes to further improve these parameters.
We tried three pretrained networks (ResNet, AlexNet and VGGNet) as backbones, but due to extensive training we were able to show that ResNet was, for our setup, the superior choice. We were further able to decide for a 2x2-stride in the last two ResNet-convolutions as well as for min-max-pooling for classification. Taken together our architecture and training-strategy proved successful and consistent on both the M2CAI2016-dataset as well as the more complex SurgToolLoc-dataset (although we could only show that for classification in this instance).

For the future it might be up to us (or others) to try the more challenging task of phase-detection. Other possible advances might lay in segmenting the images, rather than localizing objects. Additionally, further improving localization both by using peak-responses as well as by employing other exploits is a task still ahead. Further options lay in self-supervised techniques based on generative models that might achieve considerable results without relying on annotations altogether.

\textbf{Comment:} We added a ReadMe to the repository to improve legibility of the projects code.