\section{Problem Description}
The problem we strived to solve was classifying and localizing surgical instruments in endoscopic images, and in extend in videos as well. 
To that end we registered to the challenge \href{https://surgtoolloc.grand-challenge.org}{\emph{SurgToolLoc - Surgical tool localization in endoscopic videos}}, hosted by \emph{Grand Challenge} in the course of the 25th International Conference on Medical Image Computing and Computer Assisted Intervention (\emph{MICCAI}), that published their training-data on the 29th April, 2022 and excepted last entries until the 8th September, 2022. The data contains 14 possible classes and is composed of weakly annotated videos of surgical training exercises, which means that the annotation is not true for every frame, and no localization ground truth is available (more on the \emph{SurgToolLoc}-dataset in section \ref{ssec:datasets_surgtoolloc}). Due to technical difficulties and slow responses on the side of the organizers, we were unable to test our localization-performance on the test set. For that reason we trained further models on the \textit{Cholec80}-dataset(7 classes) that does not come with bounding-boxes, and a subset of it, the \textit{M2CAI16}-dataset (7 classes) that is equipped with bounding boxes, which makes comparisons of average-precision of our model to state-of-the-art-models possible (detailed descriptions in section \ref{sec:datasets}).
In a nutshell, the demands came down to the following:
\begin{itemize}
	\item classifying up to 3 out of 14 tools in one image (multi-level-classification)
	\item localizing the tools
	\item using only weakly-annotated training-data
	\item (mostly) without bounding boxes and the like
	\item Ability of the model to perform on multiple datasets
\end{itemize}

\section{Related Work}
Visual recognition with only weak annotations is a popular challenge, for one main reason: The data-availability increases strongly, when expensive annotations are no longer required, thus enabling more domains to be unlocked. Since 2015 it appeared that localization can be interpreted as merely a by-product of image-level-classification challenges \citep{localization_free}, by using a fully-convolutional approach with only some pooling in the end to assign class levels. This is already very close to our approach, and the method was applied to the COCO-dataset as well as the Pascal VOC 2012-dataset, both of which have more classes (80 and 20 respectively), and use backbones as well. This development has been going on since then, with progress in image-segmentation \citep{classpeak}, eventually sparking over to medical applications \citep{Vardazaryan}.
In all cases, backbones trained on different domains have been applied successfully, meaning that localization or segmentation-tasks were build on efficient feature-extraction. There are alternative approaches where the pre-training-phase has not been "outsourced": \cite{ross2018exploiting} showed that training a network on an auxiliary task, in their case a GAN that was supposed to recolour surgical images, proved very successful as a pre-training-technique, outperforming common backbones, in order to automate image-annotation of endoscopic images.
Other developments, that are beyond our scope, are tools that can recognize phases of an operation using long short-term memory (LSTM) units, that have feedback-connections \cite{lstm}, or networks that utilize kinematic information for segmentation task, thereby avoiding further annotations altogether \cite{da2019self}.

On the other hand, self-supervised-tools gain traction, that work in the absence of external labels using en- and decoders to extract visual cues \cite{VAE_discussion}. However, they still appear to remain an unusual choice and hard to train.

\section{ML-Tools}
Introduction of relevant machine learning tools.

\subsection{Convolutional Neural Networks}
In contrast to fully connected neural networks, convolutional neural networks (CNNs) exploit spatially local correlation by enforcing a sparse local connectivity pattern between neurons of adjacent layers: each neuron is connected to only a small region of the input volume.
This means, that the hidden layers include layers that perform convolutions using a convolution kernel. As the convolution kernel moves along the input matrix for the layer, the convolution operation generates a feature map, which in turn contributes to the input of the next layer. This may be combined with other layers such as pooling layers, fully connected layers, and normalization layers. Essentially, CNNs take advantage of the hierarchical pattern in data and assemble patterns of increasing complexity using smaller and simpler patterns embossed in their filters. As a result, the network learns filters that activate when it detects some specific type of feature at some spatial position in the input

\subsection{(Variational) Auto Encoder}
Auto encoders (AE) can be considered as a pair of neural networks, where the first part (the encoder) translates the input to a lower dimensional latent space. The second part (the decoder) then tries to reconstruct the original input using the the information provided via the latent space. Variational auto encoders learn a latent distribution (rather than representation), that can be drawn from. The decoder then proceeds as before. One advantage can be, that the variational auto encoder (VAE) avoids overfitting in the latent space. On a side note: The other main advantage of a VAE compared to an AE is that it is better suited for generative purposes.

\subsection{Backbones}
In the image-processing context, backbones are networks that provide feature-maps. Based on these feature maps, one trains a so called "head", that does the intended task of the model. Backbones are usually trained on ImageNet. Usual choices are the AlexNets or ResNets.

\subsection{Data Augmentation and Semi-Supervised Learning}
Data augmentation are techniques used to increase the amount of data by adding slightly modified copies of already existing data or newly created synthetic data from existing data. More importantly, it acts as a regularizer and helps reduce overfitting when training a machine learning model. 
Semi-supervised learning is an approach to machine learning that combines a small amount of labeled data with a large amount of unlabeled data during training.

\subsection{Gaussian Process}
Gaussian processes can be seen as an infinite-dimensional generalization of multivariate normal distributions.They are useful in statistical modelling, benefiting from properties inherited from the normal distribution. For example, if a random process is modelled as a Gaussian process, the distributions of various derived quantities can be obtained explicitly. In the context of our project we used Gaussian processes to optimize certain hyper parameters in our training. 

\subsection{Sliding Windows Approach}
The sliding windows approach means to have a classifier evaluate smaller parts of images as to whether an object is present, to then compute the place of said object in the image. It is computationally expensive, since for every part of the image a forward-pass of the classifier is needed. 
